{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "f9f85c10",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 1,
   "id": "f9f85c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aresta (0, 42): Classe prevista = baixa, Probs = {'baixa': 0.3470420837402344, 'media': 0.32766133546829224, 'alta': 0.325296550989151}\n",
      "Aresta (10, 77): Classe prevista = baixa, Probs = {'baixa': 0.40168076753616333, 'media': 0.35262376070022583, 'alta': 0.24569548666477203}\n",
      "Aresta (23, 59): Classe prevista = media, Probs = {'baixa': 0.309682697057724, 'media': 0.6305679678916931, 'alta': 0.05974934622645378}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 0. Carregar Dependências\n",
    "# -----------------------------\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Definir modelos\n",
    "# -----------------------------\n",
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        h = torch.matmul(adj, x)   # agregação\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.fc2(h)\n",
    "        return h\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_channels * 2, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, num_classes)\n",
    "        \n",
    "    def forward(self, x_i, x_j):\n",
    "        z = torch.cat([x_i, x_j], dim=-1)\n",
    "        z = F.relu(self.lin1(z))\n",
    "        return self.lin2(z)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Carregar Pesos + Artefatos\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ckpt_gcn = \"../models/gcn_state.pt\"\n",
    "ckpt_pred = \"../models/predictor_state.pt\"\n",
    "ckpt_meta = \"../models/meta.pt\"\n",
    "ckpt_graph = \"../models/graph_artifacts.pt\"\n",
    "\n",
    "# Metadados\n",
    "meta = torch.load(ckpt_meta, map_location=device)\n",
    "\n",
    "# Reconstrói modelos\n",
    "gcn_loaded = SimpleGCN(meta[\"num_features\"], meta[\"gcn_hidden\"], meta[\"gcn_out\"]).to(device)\n",
    "gcn_loaded.load_state_dict(torch.load(ckpt_gcn, map_location=device))\n",
    "gcn_loaded.eval()\n",
    "\n",
    "predictor_loaded = LinkPredictor(meta[\"gcn_out\"], meta[\"pred_hidden\"], meta[\"num_classes\"]).to(device)\n",
    "predictor_loaded.load_state_dict(torch.load(ckpt_pred, map_location=device))\n",
    "predictor_loaded.eval()\n",
    "\n",
    "# Carrega artefatos do grafo (x e edge_index)\n",
    "graph_arts = torch.load(ckpt_graph, map_location=device)\n",
    "x = graph_arts[\"x\"].to(device)\n",
    "edge_index = graph_arts[\"adj_norm\"].to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Função de Inferência\n",
    "# -----------------------------\n",
    "idx2label = {0: \"baixa\", 1: \"media\", 2: \"alta\"}\n",
    "\n",
    "@torch.no_grad()\n",
    "def classify_edges(edge_list):\n",
    "    # embeddings dos nós\n",
    "    z = gcn_loaded(x, edge_index)\n",
    "\n",
    "    i = torch.tensor([u for (u, _) in edge_list], device=z.device)\n",
    "    j = torch.tensor([v for (_, v) in edge_list], device=z.device)\n",
    "\n",
    "    # logits → aplica softmax para virar distribuição de probabilidades\n",
    "    logits = predictor_loaded(z[i], z[j])\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    results = []\n",
    "    for (u, v), p in zip(edge_list, probs):\n",
    "        pred_idx = p.argmax().item()\n",
    "        results.append({\n",
    "            \"src\": u,\n",
    "            \"dst\": v,\n",
    "            \"pred_label\": idx2label[pred_idx],\n",
    "            \"probs\": {idx2label[k]: float(p[k]) for k in range(len(p))}\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Exemplo de Uso\n",
    "# -----------------------------\n",
    "pares = [(0, 42), (10, 77), (23, 59)]\n",
    "outputs = classify_edges(pares)\n",
    "\n",
    "for o in outputs:\n",
    "    print(f\"Aresta ({o['src']}, {o['dst']}): Classe prevista = {o['pred_label']}, Probs = {o['probs']}\")"
   ]
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "venv (3.12.4)",
=======
   "display_name": "venv (3.9.6)",
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "name": "python",
   "version": "3.12.4"
=======
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
