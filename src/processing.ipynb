{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "1cc3efe8",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "1cc3efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Loss: 1.1018 | Test Acc: 0.3833 | Test F1: 0.1847\n",
      "Epoch 010 | Loss: 1.0984 | Test Acc: 0.2889 | Test F1: 0.2236\n",
      "Epoch 015 | Loss: 1.0982 | Test Acc: 0.2944 | Test F1: 0.1516\n",
      "Epoch 020 | Loss: 1.0964 | Test Acc: 0.2944 | Test F1: 0.1516\n",
      "Epoch 025 | Loss: 1.0959 | Test Acc: 0.3111 | Test F1: 0.2183\n",
      "Epoch 030 | Loss: 1.0939 | Test Acc: 0.2889 | Test F1: 0.2255\n",
      "Epoch 035 | Loss: 1.0913 | Test Acc: 0.3000 | Test F1: 0.2356\n",
      "Epoch 040 | Loss: 1.0878 | Test Acc: 0.2778 | Test F1: 0.2266\n",
      "Epoch 045 | Loss: 1.0843 | Test Acc: 0.2889 | Test F1: 0.2635\n",
      "Epoch 050 | Loss: 1.0813 | Test Acc: 0.3000 | Test F1: 0.2996\n",
      "Epoch 055 | Loss: 1.0791 | Test Acc: 0.2833 | Test F1: 0.2738\n",
      "Epoch 060 | Loss: 1.0769 | Test Acc: 0.3000 | Test F1: 0.2837\n",
      "Epoch 065 | Loss: 1.0741 | Test Acc: 0.2944 | Test F1: 0.2763\n",
      "Epoch 070 | Loss: 1.0710 | Test Acc: 0.3222 | Test F1: 0.3076\n",
      "Epoch 075 | Loss: 1.0673 | Test Acc: 0.3222 | Test F1: 0.3137\n",
      "Epoch 080 | Loss: 1.0631 | Test Acc: 0.3111 | Test F1: 0.3011\n",
      "Epoch 085 | Loss: 1.0589 | Test Acc: 0.3222 | Test F1: 0.3094\n",
      "Epoch 090 | Loss: 1.0552 | Test Acc: 0.3056 | Test F1: 0.2937\n",
      "Epoch 095 | Loss: 1.0499 | Test Acc: 0.3056 | Test F1: 0.2799\n",
      "Epoch 100 | Loss: 1.0450 | Test Acc: 0.3167 | Test F1: 0.3001\n",
      "Epoch 105 | Loss: 1.0407 | Test Acc: 0.3000 | Test F1: 0.2759\n",
      "Epoch 110 | Loss: 1.0358 | Test Acc: 0.2889 | Test F1: 0.2526\n",
      "Epoch 115 | Loss: 1.0306 | Test Acc: 0.2889 | Test F1: 0.2500\n",
      "Epoch 120 | Loss: 1.0251 | Test Acc: 0.2889 | Test F1: 0.2443\n",
      "Epoch 125 | Loss: 1.0177 | Test Acc: 0.3056 | Test F1: 0.2719\n",
      "Epoch 130 | Loss: 1.0104 | Test Acc: 0.3222 | Test F1: 0.3016\n",
      "Epoch 135 | Loss: 1.0042 | Test Acc: 0.3222 | Test F1: 0.2993\n",
      "Epoch 140 | Loss: 0.9970 | Test Acc: 0.3111 | Test F1: 0.2940\n",
      "Epoch 145 | Loss: 0.9915 | Test Acc: 0.3167 | Test F1: 0.3006\n",
      "Epoch 150 | Loss: 0.9851 | Test Acc: 0.3222 | Test F1: 0.2855\n",
      "Epoch 155 | Loss: 0.9800 | Test Acc: 0.3389 | Test F1: 0.3193\n",
      "Epoch 160 | Loss: 0.9752 | Test Acc: 0.3056 | Test F1: 0.3002\n",
      "Epoch 165 | Loss: 0.9702 | Test Acc: 0.3167 | Test F1: 0.2849\n",
      "Epoch 170 | Loss: 0.9641 | Test Acc: 0.3056 | Test F1: 0.2695\n",
      "Epoch 175 | Loss: 0.9587 | Test Acc: 0.3056 | Test F1: 0.2743\n",
      "Epoch 180 | Loss: 0.9529 | Test Acc: 0.3056 | Test F1: 0.2733\n",
      "Epoch 185 | Loss: 0.9472 | Test Acc: 0.3000 | Test F1: 0.2971\n",
      "Epoch 190 | Loss: 0.9413 | Test Acc: 0.3000 | Test F1: 0.2972\n",
      "Epoch 195 | Loss: 0.9370 | Test Acc: 0.3056 | Test F1: 0.3024\n",
      "Epoch 200 | Loss: 0.9325 | Test Acc: 0.3111 | Test F1: 0.3075\n",
      "Epoch 205 | Loss: 0.9290 | Test Acc: 0.3111 | Test F1: 0.3073\n",
      "Epoch 210 | Loss: 0.9251 | Test Acc: 0.3222 | Test F1: 0.3172\n",
      "Epoch 215 | Loss: 0.9213 | Test Acc: 0.3000 | Test F1: 0.2958\n",
      "Epoch 220 | Loss: 0.9182 | Test Acc: 0.2944 | Test F1: 0.2907\n",
      "Epoch 225 | Loss: 0.9175 | Test Acc: 0.3056 | Test F1: 0.2962\n",
      "Epoch 230 | Loss: 0.9158 | Test Acc: 0.2889 | Test F1: 0.2832\n",
      "Epoch 235 | Loss: 0.9108 | Test Acc: 0.2944 | Test F1: 0.2915\n",
      "Epoch 240 | Loss: 0.9114 | Test Acc: 0.2778 | Test F1: 0.2517\n",
      "Epoch 245 | Loss: 0.9062 | Test Acc: 0.2833 | Test F1: 0.2609\n",
      "Epoch 250 | Loss: 0.9044 | Test Acc: 0.2889 | Test F1: 0.2653\n",
      "Epoch 255 | Loss: 0.9026 | Test Acc: 0.2889 | Test F1: 0.2653\n",
      "Epoch 260 | Loss: 0.9008 | Test Acc: 0.2889 | Test F1: 0.2654\n",
      "Epoch 265 | Loss: 0.8996 | Test Acc: 0.2833 | Test F1: 0.2575\n",
      "Epoch 270 | Loss: 0.8982 | Test Acc: 0.2778 | Test F1: 0.2537\n",
      "Epoch 275 | Loss: 0.8973 | Test Acc: 0.2833 | Test F1: 0.2649\n",
      "Epoch 280 | Loss: 0.8954 | Test Acc: 0.2778 | Test F1: 0.2594\n",
      "Epoch 285 | Loss: 0.8938 | Test Acc: 0.2944 | Test F1: 0.2850\n",
      "Epoch 290 | Loss: 0.8920 | Test Acc: 0.2889 | Test F1: 0.2806\n",
      "Epoch 295 | Loss: 0.8911 | Test Acc: 0.3111 | Test F1: 0.3013\n",
      "Epoch 300 | Loss: 0.8899 | Test Acc: 0.3167 | Test F1: 0.3060\n",
      "Epoch 305 | Loss: 0.8875 | Test Acc: 0.3111 | Test F1: 0.3008\n",
      "Epoch 310 | Loss: 0.8850 | Test Acc: 0.3111 | Test F1: 0.3011\n",
      "Epoch 315 | Loss: 0.8858 | Test Acc: 0.3111 | Test F1: 0.3010\n",
      "Epoch 320 | Loss: 0.8861 | Test Acc: 0.3111 | Test F1: 0.3010\n",
      "Epoch 325 | Loss: 0.8824 | Test Acc: 0.3167 | Test F1: 0.3055\n",
      "Epoch 330 | Loss: 0.8822 | Test Acc: 0.3167 | Test F1: 0.3077\n",
      "Epoch 335 | Loss: 0.8791 | Test Acc: 0.3167 | Test F1: 0.3077\n",
      "Epoch 340 | Loss: 0.8783 | Test Acc: 0.3167 | Test F1: 0.3078\n",
      "Epoch 345 | Loss: 0.8766 | Test Acc: 0.3167 | Test F1: 0.3069\n",
      "Epoch 350 | Loss: 0.8752 | Test Acc: 0.3167 | Test F1: 0.3069\n",
      "Epoch 355 | Loss: 0.8759 | Test Acc: 0.3278 | Test F1: 0.3146\n",
      "Epoch 360 | Loss: 0.8743 | Test Acc: 0.3389 | Test F1: 0.3236\n",
      "Epoch 365 | Loss: 0.8739 | Test Acc: 0.3333 | Test F1: 0.3210\n",
      "Epoch 370 | Loss: 0.8727 | Test Acc: 0.3222 | Test F1: 0.3118\n",
      "Epoch 375 | Loss: 0.8720 | Test Acc: 0.3167 | Test F1: 0.3050\n",
      "Epoch 380 | Loss: 0.8718 | Test Acc: 0.3222 | Test F1: 0.3097\n",
      "Epoch 385 | Loss: 0.8706 | Test Acc: 0.3222 | Test F1: 0.3081\n",
      "Epoch 390 | Loss: 0.8689 | Test Acc: 0.3278 | Test F1: 0.3150\n",
      "Epoch 395 | Loss: 0.8685 | Test Acc: 0.3111 | Test F1: 0.2990\n",
      "Epoch 400 | Loss: 0.8670 | Test Acc: 0.3167 | Test F1: 0.3050\n",
      "Epoch 405 | Loss: 0.8674 | Test Acc: 0.3111 | Test F1: 0.2975\n",
      "Epoch 410 | Loss: 0.8675 | Test Acc: 0.3111 | Test F1: 0.2990\n",
      "Epoch 415 | Loss: 0.8675 | Test Acc: 0.3167 | Test F1: 0.3050\n",
      "Epoch 420 | Loss: 0.8679 | Test Acc: 0.3111 | Test F1: 0.2991\n",
      "Epoch 425 | Loss: 0.8647 | Test Acc: 0.3167 | Test F1: 0.3036\n",
      "Epoch 430 | Loss: 0.8629 | Test Acc: 0.3222 | Test F1: 0.3108\n",
      "Epoch 435 | Loss: 0.8616 | Test Acc: 0.3167 | Test F1: 0.3001\n",
      "Epoch 440 | Loss: 0.8611 | Test Acc: 0.3222 | Test F1: 0.3085\n",
      "Epoch 445 | Loss: 0.8586 | Test Acc: 0.3278 | Test F1: 0.3154\n",
      "Epoch 450 | Loss: 0.8577 | Test Acc: 0.3222 | Test F1: 0.3045\n",
      "Epoch 455 | Loss: 0.8570 | Test Acc: 0.3167 | Test F1: 0.2996\n",
      "Epoch 460 | Loss: 0.8562 | Test Acc: 0.3167 | Test F1: 0.2996\n",
      "Epoch 465 | Loss: 0.8550 | Test Acc: 0.3222 | Test F1: 0.3060\n",
      "Epoch 470 | Loss: 0.8542 | Test Acc: 0.3222 | Test F1: 0.3085\n",
      "Epoch 475 | Loss: 0.8564 | Test Acc: 0.3056 | Test F1: 0.2891\n",
      "Epoch 480 | Loss: 0.8544 | Test Acc: 0.3111 | Test F1: 0.2964\n",
      "Epoch 485 | Loss: 0.8533 | Test Acc: 0.3222 | Test F1: 0.3055\n",
      "Epoch 490 | Loss: 0.8522 | Test Acc: 0.3056 | Test F1: 0.2891\n",
      "Epoch 495 | Loss: 0.8512 | Test Acc: 0.3222 | Test F1: 0.3051\n",
      "Modelo salvo em ../models/gcn_state.pt\n",
      "Modelo salvo em ../models/predictor_state.pt\n",
      "Modelo salvo em ../models/meta.pt\n",
      "Modelo salvo em ../models/graph_artifacts.pt\n",
      "Métricas salvas em ../results/result.json\n"
     ]
    }
   ],
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
   "source": [
    "# -----------------------------\n",
    "# 0. Carregar Dependências\n",
    "# -----------------------------\n",
<<<<<<< HEAD
    "import random\n",
=======
    "import os\n",
    "import pandas as pd\n",
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Definir modelos\n",
    "# -----------------------------\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int) -> None:\n",
    "        \"\"\"Init function for the GCN model.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Dimension of the input features\n",
    "            hidden_dim: Dimension of the hidden layer\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward function for the GCN model.\n",
    "\n",
    "        Args:\n",
    "            x: Input node features\n",
    "            edge_index: Graph edge indices (COO)\n",
    "\n",
    "        Returns:\n",
    "            Output (updated) node features with message passing.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class EdgeMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        \"\"\"Init function for the EdgeMLP model.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Dimension of the input features (concatenated embeddings)\n",
    "            hidden_dim: Dimension of the hidden layer\n",
    "            output_dim: Dimension of the output (number of classes)\n",
    "        \"\"\"\n",
    "        super(EdgeMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward function for the EdgeMLP model.\n",
    "\n",
    "        Args:\n",
    "            x: Input edge features (concatenated node embeddings)\n",
    "\n",
    "        Returns:\n",
    "            Output edge class logits\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a single dummy graph\n",
    "def create_dummy_graph(\n",
    "    max_num_nodes: int, feature_dim: int, num_classes: int\n",
    ") -> tuple[int, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Create a dummy graph with random edges and labels.\n",
    "\n",
    "    Args:\n",
    "        max_num_nodes: Maximum number of nodes in the graph\n",
    "        feature_dim: Dimension of the node features\n",
    "        num_classes: Number of target classes\n",
    "\n",
<<<<<<< HEAD
    "    Returns:\n",
    "        num_nodes: Number of nodes in the graph\n",
    "        node_features: Node features tensor\n",
    "        edge_index: Graph edge indices tensor\n",
    "        edge_labels: Edge labels tensor\n",
=======
    "print(\"Modelo salvo em ../models/gcn_state.pt\")\n",
    "print(\"Modelo salvo em ../models/predictor_state.pt\")\n",
    "print(\"Modelo salvo em ../models/meta.pt\")\n",
    "print(\"Modelo salvo em ../models/graph_artifacts.pt\")\n",
>>>>>>> 0a56692372943491d14aaee8431daabe784e1b20
    "\n",
    "    \"\"\"\n",
    "    # Randomly create nodes and edges\n",
    "    num_nodes = torch.randint(2, max_num_nodes, (1,)).item()\n",
    "    node_features = torch.randn(num_nodes, feature_dim)\n",
    "\n",
    "    num_edges = torch.randint(1, num_nodes * 2, (1,)).item()\n",
    "    edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "\n",
    "    # Assign random labels to edges\n",
    "    edge_labels = torch.randint(0, num_classes, (num_edges,))\n",
    "\n",
    "    return num_nodes, node_features, edge_index, edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the total number of entities and embedding dimensions\n",
    "num_total_entities = 32  # Total number of entities\n",
    "embedding_dim = 16  # Dimension of each embedding vector\n",
    "num_classes = 2  # Number of target classes (for edge classification)\n",
    "\n",
    "# Parameters\n",
    "hidden_dim = 32\n",
    "num_graphs = 256  # Number of graphs in the dataset\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Initialize the models\n",
    "gcn_model = GCN(input_dim=embedding_dim, hidden_dim=hidden_dim)\n",
    "edge_mlp = EdgeMLP(\n",
    "    input_dim=2 * hidden_dim, hidden_dim=hidden_dim, output_dim=num_classes\n",
    ")\n",
    "\n",
    "# Create dataset\n",
    "dataset = [\n",
    "    create_dummy_graph(num_total_entities, embedding_dim, num_classes)\n",
    "    for _ in range(num_graphs)\n",
    "]\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(gcn_model.parameters()) + list(edge_mlp.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # iid shuffle of the dataset\n",
    "    random.shuffle(dataset)\n",
    "    batches = [dataset[i : i + batch_size] for i in range(0, len(dataset), batch_size)]\n",
    "\n",
    "    for batch in batches:\n",
    "        num_nodes_all = [graph[0] for graph in batch]\n",
    "        node_features_all = [graph[1] for graph in batch]\n",
    "        node_feature_batch = torch.cat(node_features_all, dim=0)\n",
    "        edge_index_all = [graph[2] for graph in batch]\n",
    "        edge_labels_all = [graph[3] for graph in batch]\n",
    "        edge_labels_batch = torch.cat(edge_labels_all, dim=0)\n",
    "\n",
    "        # This is a bit tricky: we need to update the edge indices to reflect the new\n",
    "        # node ordering. We do this by adding the sum of the number of nodes in the\n",
    "        # previous graphs. This is how batching is done in GNNs.\n",
    "        edge_index_batch = []\n",
    "        num_nodes_sum = 0\n",
    "        for i, edge_index in enumerate(edge_index_all):\n",
    "            edge_index_batch.append(edge_index + num_nodes_sum)\n",
    "            num_nodes_sum += num_nodes_all[i]\n",
    "\n",
    "        edge_index_batch = torch.cat(edge_index_batch, dim=1)\n",
    "\n",
    "        # Forward pass through GCN to get node embeddings\n",
    "        node_embeddings_out = gcn_model(node_feature_batch, edge_index_batch)\n",
    "\n",
    "        # Prepare edge features by concatenating the embeddings of the head and tail nodes\n",
    "        edge_embeddings = torch.cat(\n",
    "            [\n",
    "                node_embeddings_out[edge_index_batch[0]],\n",
    "                node_embeddings_out[edge_index_batch[1]],\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Forward pass through MLP for edge classification\n",
    "        out = edge_mlp(edge_embeddings)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(out, edge_labels_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        total_loss += loss.item()\n",
    "        preds = out.argmax(dim=1)\n",
    "        total_correct += (preds == edge_labels_batch).sum().item()\n",
    "        total_samples += edge_labels_batch.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(batches)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
