{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71e6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n",
      "d:\\Visual Code\\GNN\\venv\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010, Loss: 0.6276, Val AUC: 0.6331, Test AUC: 0.6202\n",
      "Epoch 020, Loss: 0.5101, Val AUC: 0.7674, Test AUC: 0.7418\n",
      "Epoch 030, Loss: 0.3537, Val AUC: 0.8298, Test AUC: 0.8221\n",
      "Epoch 040, Loss: 0.2803, Val AUC: 0.8417, Test AUC: 0.8514\n",
      "Epoch 050, Loss: 0.2376, Val AUC: 0.8364, Test AUC: 0.8512\n",
      "Epoch 060, Loss: 0.1986, Val AUC: 0.8508, Test AUC: 0.8616\n",
      "Epoch 070, Loss: 0.1741, Val AUC: 0.8645, Test AUC: 0.8713\n",
      "Epoch 080, Loss: 0.1564, Val AUC: 0.8657, Test AUC: 0.8710\n",
      "Epoch 090, Loss: 0.1517, Val AUC: 0.8667, Test AUC: 0.8729\n",
      "Epoch 100, Loss: 0.1491, Val AUC: 0.8648, Test AUC: 0.8705\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 0. Carregar Dependências\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Carregar Dataset\n",
    "# -----------------------------\n",
    "os.makedirs(\"../datasets\", exist_ok=True)\n",
    "dataset = Planetoid(root=\"../datasets/Cora\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "# divide arestas em treino/val/test\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Definir Modelo GCN\n",
    "# -----------------------------\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Link Predictor\n",
    "# -----------------------------\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels=1):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(in_channels * 2, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        z = torch.cat([x_i, x_j], dim=-1)\n",
    "        z = F.relu(self.lin1(z))\n",
    "        z = torch.sigmoid(self.lin2(z))\n",
    "        return z.view(-1)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Funções de treino e teste\n",
    "# -----------------------------\n",
    "def train(gcn, predictor, optimizer, data):\n",
    "    gcn.train()\n",
    "    predictor.train()\n",
    "\n",
    "    z = gcn(data.x, data.train_pos_edge_index)\n",
    "\n",
    "    # negativos amostrados\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1),\n",
    "    )\n",
    "\n",
    "    # predições positivas e negativas\n",
    "    pos_pred = predictor(z[data.train_pos_edge_index[0]], z[data.train_pos_edge_index[1]])\n",
    "    neg_pred = predictor(z[neg_edge_index[0]], z[neg_edge_index[1]])\n",
    "\n",
    "    preds = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "    # rótulos diretos (sem função auxiliar)\n",
    "    labels = torch.cat([\n",
    "        torch.ones(pos_pred.size(0), device=preds.device, dtype=preds.dtype),\n",
    "        torch.zeros(neg_pred.size(0), device=preds.device, dtype=preds.dtype)\n",
    "    ], dim=0)\n",
    "\n",
    "    loss = F.binary_cross_entropy(preds, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(gcn, predictor, data):\n",
    "    gcn.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    z = gcn(data.x, data.train_pos_edge_index)\n",
    "\n",
    "    def eval_edges(pos_edge_index, neg_edge_index):\n",
    "        pos_pred = predictor(z[pos_edge_index[0]], z[pos_edge_index[1]])\n",
    "        neg_pred = predictor(z[neg_edge_index[0]], z[neg_edge_index[1]])\n",
    "        preds = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        labels = torch.cat([\n",
    "            torch.ones(pos_pred.size(0), device=preds.device, dtype=preds.dtype),\n",
    "            torch.zeros(neg_pred.size(0), device=preds.device, dtype=preds.dtype)\n",
    "        ], dim=0)\n",
    "\n",
    "        auc = roc_auc_score(labels.cpu(), preds.cpu())\n",
    "        return auc\n",
    "\n",
    "    auc_val = eval_edges(data.val_pos_edge_index, data.val_neg_edge_index)\n",
    "    auc_test = eval_edges(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "\n",
    "    return auc_val, auc_test\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Treinar modelo\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gcn = GCN(dataset.num_features, 64, 32).to(device)\n",
    "predictor = LinkPredictor(32, 64).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(gcn.parameters()) + list(predictor.parameters()), lr=0.01\n",
    ")\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(gcn, predictor, optimizer, data)\n",
    "    if epoch % 10 == 0:\n",
    "        val_auc, test_auc = test(gcn, predictor, data)\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Salvar Modelo \n",
    "# -----------------------------\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "ckpt_gcn = \"../models/gcn_state.pt\"\n",
    "ckpt_pred = \"../models/predictor_state.pt\"\n",
    "ckpt_meta = \"../models/meta.pt\"\n",
    "ckpt_graph = \"../models/graph_artifacts.pt\"\n",
    "\n",
    "# Salva pesos\n",
    "torch.save(gcn.state_dict(), ckpt_gcn)\n",
    "torch.save(predictor.state_dict(), ckpt_pred)\n",
    "\n",
    "# Salva metadados\n",
    "torch.save({\n",
    "    \"num_features\": dataset.num_features,\n",
    "    \"gcn_hidden\": 64,\n",
    "    \"gcn_out\": 32,\n",
    "    \"pred_hidden\": 64\n",
    "}, ckpt_meta)\n",
    "\n",
    "# Salva artefatos do grafo\n",
    "torch.save({\n",
    "    \"x\": data.x.cpu(),\n",
    "    \"train_pos_edge_index\": data.train_pos_edge_index.cpu()\n",
    "}, ckpt_graph)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Métricas adicionais \n",
    "# -----------------------------\n",
    "gcn.eval(); predictor.eval()\n",
    "with torch.no_grad():\n",
    "    z = gcn(data.x, data.train_pos_edge_index)\n",
    "\n",
    "    # Val\n",
    "    pos = predictor(z[data.val_pos_edge_index[0]], z[data.val_pos_edge_index[1]]).cpu().numpy()\n",
    "    neg = predictor(z[data.val_neg_edge_index[0]], z[data.val_neg_edge_index[1]]).cpu().numpy()\n",
    "    probs  = np.concatenate([pos, neg], axis=0)\n",
    "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)], axis=0)\n",
    "    preds  = (probs >= 0.5).astype(int)\n",
    "    val_acc  = accuracy_score(labels, preds)\n",
    "    val_prec = precision_score(labels, preds, zero_division=0)\n",
    "    val_rec  = recall_score(labels, preds, zero_division=0)\n",
    "    val_f1   = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    # Test\n",
    "    pos = predictor(z[data.test_pos_edge_index[0]], z[data.test_pos_edge_index[1]]).cpu().numpy()\n",
    "    neg = predictor(z[data.test_neg_edge_index[0]], z[data.test_neg_edge_index[1]]).cpu().numpy()\n",
    "    probs  = np.concatenate([pos, neg], axis=0)\n",
    "    labels = np.concatenate([np.ones_like(pos), np.zeros_like(neg)], axis=0)\n",
    "    preds  = (probs >= 0.5).astype(int)\n",
    "    test_acc  = accuracy_score(labels, preds)\n",
    "    test_prec = precision_score(labels, preds, zero_division=0)\n",
    "    test_rec  = recall_score(labels, preds, zero_division=0)\n",
    "    test_f1   = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "# Monta dicionário e salva em JSON\n",
    "results = {\n",
    "    \"threshold\": 0.5,\n",
    "    \"val\": {\n",
    "        \"accuracy\": float(val_acc),\n",
    "        \"precision\": float(val_prec),\n",
    "        \"recall\": float(val_rec),\n",
    "        \"f1\": float(val_f1),\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"accuracy\": float(test_acc),\n",
    "        \"precision\": float(test_prec),\n",
    "        \"recall\": float(test_rec),\n",
    "        \"f1\": float(test_f1),\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "with open(\"../results/result.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
